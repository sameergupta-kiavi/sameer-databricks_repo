{"cells":[{"cell_type":"code","source":["import json\n\ndbutils.widgets.text(\"src_table\", \"\")\nsrc_table = dbutils.widgets.get(\"src_table\")\n \ndbutils.widgets.text(\"select_columns\", \"[]\")\nselect_columns = json.loads(dbutils.widgets.get(\"select_columns\"))\n\ndbutils.widgets.text(\"filter_sql_expression\", \"\")\nfilter_sql_expression = dbutils.widgets.get(\"filter_sql_expression\")\n\ndbutils.widgets.text(\"feature_store_table\", \"\")\nfeature_store_table = dbutils.widgets.get(\"feature_store_table\")\n\ndbutils.widgets.text(\"feature_store_primary_keys\", \"[]\")\nfeature_store_primary_keys = dbutils.widgets.get(\"feature_store_primary_keys\")\n\ndbutils.widgets.text(\"feature_store_timestamp_keys\", \"[]\")\nfeature_store_timestamp_keys = dbutils.widgets.get(\"feature_store_timestamp_keys\")\n\ndbutils.widgets.text(\"feature_store_partition_columns\", \"[]\")\nfeature_store_partition_columns = json.loads(dbutils.widgets.get(\"feature_store_partition_columns\"))\n\ndbutils.widgets.text(\"feature_store_description\", \"\")\nfeature_store_description = dbutils.widgets.get(\"feature_store_description\")\n\nassert src_table\nassert feature_store_table\n\nprint(src_table, select_columns, filter_sql_expression, feature_store_table, feature_store_primary_keys, feature_store_timestamp_keys, feature_store_partition_columns, feature_store_description)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c3823b50-5d2a-44d1-a231-d5ad3383eb84","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from databricks import feature_store"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28fa7445-070a-402d-a1a1-3d291aaa3bbd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.format(\"delta\").load(src_table)\nif select_columns:\n    df = df.select(select_columns)\nif filter_sql_expression:\n    df = df.filter(filter_sql_expression)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8a081c37-2b89-4009-ac77-8462beb65f74","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# To improve query speed, Delta Lake on Databricks supports the ability to optimize the layout of data stored in cloud storage. Delta Lake on Databricks supports the algorithms called Z-Ordering.\n# In ordinary delta lake table we externally had to apply these algorithms to optimize the delta tables. But in feature store delta table Z-ordering is implicitly applied on primary_keys of the table.\n# This Z-ordering is only applied on columns with int datatype.\n# We disable Z-ordering in feature_table when its primary_key is of string data_type using the command set spark.databricks.delta.optimize.zorder.checkStatsCollection.enabled = false\n\nfeature_store_primary_keys = [feature_store_primary_keys]\nfeature_store_timestamp_keys = [feature_store_timestamp_keys]\nprimary_key_dtype = df.select(feature_store_primary_keys).dtypes\n\nfor key, key_data_type in primary_key_dtype:\n    if key_data_type == 'string':\n        spark.sql('set spark.databricks.delta.optimize.zorder.checkStatsCollection.enabled = false')\n        break\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24a9a3d5-f590-4f89-a090-15d9a33751a7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["fs = feature_store.FeatureStoreClient()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e6c8487-804f-48f9-a183-dd49546e7ca8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Write to the existing feature store table or create a brand new one"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5112c2de-4184-4291-bb44-1b7eebac12da","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["if spark.catalog.tableExists(feature_store_table):\n    fs.write_table(\n        name=feature_store_table,\n        df=df,\n        mode=\"merge\"\n    )\nelse:\n    assert feature_store_table\n    assert feature_store_primary_keys\n    assert feature_store_description\n    feature_table = fs.create_table(\n        name=feature_store_table,\n        primary_keys=feature_store_primary_keys,\n        timestamp_keys=feature_store_timestamp_keys,\n        partition_columns=feature_store_partition_columns,\n        description=feature_store_description,\n        df=df,\n        schema=df.schema,\n    )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9e9a5bf-7210-4aa4-ad03-a184f5d67c4c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"feature_store.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1070981632078329}},"nbformat":4,"nbformat_minor":0}
